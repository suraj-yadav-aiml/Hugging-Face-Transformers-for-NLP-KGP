{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bplrTgLWqW27",
        "outputId": "ecda9ba7-8dcf-4594-d6b5-f96ffdac929e"
      },
      "outputs": [],
      "source": [
        "# !pip install -U transformers\n",
        "# !pip install -U accelerate\n",
        "# !pip install -U datasets\n",
        "# !pip install -U bertviz\n",
        "# !pip install -U umap-learn\n",
        "# !pip install -U sentencepiece\n",
        "# !pip install -U urllib3\n",
        "# !pip install py7zr\n",
        "# !pip install -U pillow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKpnyC-BqW29"
      },
      "source": [
        "# Image classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxDwPWAxqW2-"
      },
      "source": [
        "## Load Dog and Cats dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGjSuKFVqW2-",
        "outputId": "900f474f-c3cb-4c7c-e2e8-006c2f8cb50d"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"microsoft/cats_vs_dogs\", split=['train'], \n",
        "                       trust_remote_code=True, ignore_verifications=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# select only 10% of the dataset\n",
        "dataset = dataset[0].train_test_split(train_size=0.2, seed=42)['train']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset\n",
        "dataset = dataset.train_test_split(test_size=0.3, seed=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoTVrHVuqW2_",
        "outputId": "dbdc60c7-5f20-421c-ec85-9d3157977763"
      },
      "outputs": [],
      "source": [
        "dataset[\"train\"][0]['image'].size\n",
        "dataset[\"train\"][0]['image']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# resize the images to 224x224\n",
        "def resize_image(example, size=(224, 224)):\n",
        "    image = example['image'] \n",
        "    image = image.resize(size)\n",
        "    example['image'] = image\n",
        "    return example\n",
        "\n",
        "dataset = dataset.map(resize_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTGrwi3iqW2_"
      },
      "source": [
        "Each example in the dataset has two fields:\n",
        "\n",
        "- `image`: a PIL image of the food item\n",
        "- `label`: the label class of the food item\n",
        "\n",
        "To make it easier for the model to get the label name from the label id, create a dictionary that maps the label name\n",
        "to an integer and vice versa:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7llysjwYqW2_"
      },
      "outputs": [],
      "source": [
        "labels = dataset[\"train\"].features[\"labels\"].names\n",
        "label2id, id2label = dict(), dict()\n",
        "for i, label in enumerate(labels):\n",
        "    label2id[label] = str(i)\n",
        "    id2label[str(i)] = label\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmuSm3ZcqW2_"
      },
      "source": [
        "Now you can convert the label id to a label name:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "UcUnxsDFqW2_",
        "outputId": "2c190157-8dbd-4fbb-9ceb-d0f19b5754d7"
      },
      "outputs": [],
      "source": [
        "print(id2label)\n",
        "print(label2id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRa_JZl-qW2_"
      },
      "source": [
        "## Preprocess"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5CBAIkZqW2_"
      },
      "source": [
        "The next step is to load a ViT image processor to process the image into a tensor:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCxN3xkkqW2_",
        "outputId": "a9019523-5102-49f2-937d-5183c244b706"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoImageProcessor\n",
        "import torch\n",
        "\n",
        "# https://huggingface.co/google/vit-base-patch16-224-in21k\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "# checkpoint = \"google/vit-base-patch16-224-in21k\"\n",
        "# checkpoint = \"apple/mobilevitv2-1.0-imagenet1k-256\"\n",
        "checkpoint = \"microsoft/resnet-50\"\n",
        "image_processor = AutoImageProcessor.from_pretrained(checkpoint)\n",
        "\n",
        "# image_processor = AutoImageProcessor.from_pretrained(\"apple/mobilevitv2-1.0-imagenet1k-256\")\n",
        "# model = MobileViTV2ForImageClassification.from_pretrained(\"apple/mobilevitv2-1.0-imagenet1k-256\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrhtiFSzqW3A"
      },
      "source": [
        "Now create a batch of examples using [DefaultDataCollator](https://huggingface.co/docs/transformers/main/en/main_classes/data_collator#transformers.DefaultDataCollator). Unlike other data collators in ðŸ¤— Transformers, the `DefaultDataCollator` does not apply additional preprocessing such as padding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SR4Y4T96qW3A"
      },
      "outputs": [],
      "source": [
        "from transformers import DefaultDataCollator\n",
        "\n",
        "data_collator = DefaultDataCollator()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trFJPE16qW3A"
      },
      "source": [
        "## Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IK4hTI1MqW3A"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "\n",
        "accuracy = evaluate.load(\"accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDzRMkK6qW3A"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return accuracy.compute(predictions=predictions, references=labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgebWBBkqW3A"
      },
      "source": [
        "Your `compute_metrics` function is ready to go now, and you'll return to it when you set up your training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNOCmVzmqW3A"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEJ6XPwzqW3A",
        "outputId": "156fbb5e-b5ce-4920-8e3c-b8c354840932"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uuc3tSmktAQO"
      },
      "outputs": [],
      "source": [
        "from torchvision.transforms import RandomResizedCrop, Compose, ToTensor\n",
        "\n",
        "# normalize = Normalize(mean=image_processor.image_mean, std=image_processor.image_std)\n",
        "size = (\n",
        "    image_processor.size[\"shortest_edge\"]\n",
        "    if \"shortest_edge\" in image_processor.size\n",
        "    else (image_processor.size[\"height\"], image_processor.size[\"width\"])\n",
        ")\n",
        "_transforms = Compose([RandomResizedCrop(size), ToTensor()])\n",
        "\n",
        "def transforms(examples):\n",
        "    examples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"image\"]]\n",
        "    # del examples[\"image\"]\n",
        "    return examples\n",
        "\n",
        "# dataset = dataset.with_transform(transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = dataset.map(transforms, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AutoModelForImageClassification, TrainingArguments, Trainer\n",
        "\n",
        "model = AutoModelForImageClassification.from_pretrained(\n",
        "    checkpoint,\n",
        "    num_labels=len(labels),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        "    ignore_mismatched_sizes = True\n",
        ").to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "Cga7LU7DqW3A",
        "outputId": "dcb37aba-0782-4bf7-ed60-329b39b4d07a"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"dog_cat_classification\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=5e-5,\n",
        "    per_device_train_batch_size=64,\n",
        "    per_device_eval_batch_size=64,\n",
        "    num_train_epochs=3,\n",
        "    load_best_model_at_end=True,\n",
        "    gradient_accumulation_steps=100,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    eval_dataset=dataset[\"test\"],\n",
        "    tokenizer=image_processor,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer.save_model(\"dog_cat_classification\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTUlWWdWqW3D"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GddfQRWaqW3D"
      },
      "source": [
        "Great, now that you've fine-tuned a model, you can use it for inference!\n",
        "\n",
        "Load an image you'd like to run inference on:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WunKtnaSqW3D"
      },
      "outputs": [],
      "source": [
        "# load dog image from online url\n",
        "\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "\n",
        "url = \"https://cdn.pixabay.com/photo/2016/12/13/05/15/puppy-1903313_640.jpg\"\n",
        "response = requests.get(url)\n",
        "image = Image.open(BytesIO(response.content))\n",
        "\n",
        "# show in 300x300\n",
        "image = image.resize((224, 224))\n",
        "image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHca-esjqW3D",
        "outputId": "2f313560-b52a-4ceb-a0b0-232b6ecd5eac"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"image-classification\", model=\"dog_cat_classification\", device=device)\n",
        "classifier(image)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
